{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4d/f5lz4rj56ws3v2hlc19c60t80000gn/T/ipykernel_10968/3981918931.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "from functions.utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We generate the synthetic graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param = {\n",
    "    \"min_nodes\": 5000,\n",
    "    \"max_nodes\": 10000,\n",
    "    \"num_of_graphs\": 15,\n",
    "    \"graph_types\": [\"ER\",\"SF\",\"GRP\"],\n",
    "    \"generation_seeds\": [10]\n",
    "}\n",
    "\n",
    "for graph_type in param[\"graph_types\"]:\n",
    "\n",
    "    for seed in param[\"generation_seeds\"]:\n",
    "        \n",
    "        random.seed(seed)\n",
    "\n",
    "        print(f\"Generating {param['num_of_graphs']} {graph_type} graphs\")\n",
    "        list_bet_data = list()\n",
    "        for i in range(param['num_of_graphs']):\n",
    "            print(f\"{datetime.now().strftime('%d/%m/%Y %H:%M:%S')}: Graph index:{i+1}/{param['num_of_graphs']}\")\n",
    "            g_nx = create_graph(graph_type,param['min_nodes'],param['max_nodes'])\n",
    "            \n",
    "            if nx.number_of_isolates(g_nx)>0:\n",
    "                g_nx.remove_nodes_from(list(nx.isolates(g_nx)))\n",
    "                g_nx = nx.convert_node_labels_to_integers(g_nx)\n",
    "\n",
    "            g_nkit = nx2nkit(g_nx)\n",
    "            bet_dict = cal_exact_bet(g_nkit)\n",
    "            deg_dict = cal_exact_degree(g_nkit)\n",
    "            list_bet_data.append([g_nx,bet_dict,deg_dict])\n",
    "\n",
    "        fname_bet = f\"./delivery/graphs/{graph_type}_{param['num_of_graphs']}_graphs_{param['max_nodes']}_{param['min_nodes']}_nodes_{seed}_genseed.pickle\"    \n",
    "\n",
    "        with open(fname_bet,\"wb\") as fopen:\n",
    "            pickle.dump(list_bet_data,fopen)\n",
    "\n",
    "print(\"Graphs saved\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"adj_size\" : 10000,\n",
    "    \"num_train\" : 5,\n",
    "    \"num_test\" : 10,\n",
    "    \"num_copies\": [100],\n",
    "    \"graph_files\": [\"ER_15_graphs_10000_5000_nodes\",\n",
    "                    \"SF_15_graphs_10000_5000_nodes\",\n",
    "                    \"GRP_15_graphs_10000_5000_nodes\"],\n",
    "    \"split_seeds\": [10],\n",
    "    \"generation_seeds\": [10]\n",
    "}\n",
    "\n",
    "\n",
    "for graph_file in param[\"graph_files\"]:\n",
    "    for genseed in param[\"generation_seeds\"]:\n",
    "        for num_copies in param[\"num_copies\"]:\n",
    "            for splitseed in param[\"split_seeds\"]:\n",
    "        \n",
    "                with open(f\"./delivery/graphs/{graph_file}_{genseed}_genseed.pickle\",\"rb\") as fopen:\n",
    "                    list_data = pickle.load(fopen)\n",
    "\n",
    "                num_graph = len(list_data)\n",
    "                assert param[\"num_train\"]+param[\"num_test\"] == num_graph,\"Required split size doesn't match number of graphs in pickle file.\"\n",
    "            \n",
    "                #For training split\n",
    "                if param[\"num_train\"] > 0:\n",
    "                    random.seed(splitseed)\n",
    "                    list_graph, list_n_sequence, list_node_num, cent_mat, deg_mat = create_dataset(list_data[:param[\"num_train\"]],num_copies = num_copies, adj_size=param[\"adj_size\"])\n",
    "\n",
    "                    with open(f\"./delivery/data_splits/train/{graph_file}_{genseed}_genseed_{param['num_train']}_train_{num_copies}_copies_{param['adj_size']}_size_{splitseed}_splitseed.pickle\",\"wb\") as fopen:\n",
    "                        pickle.dump([list_graph,list_n_sequence,list_node_num,cent_mat, deg_mat],fopen)\n",
    "\n",
    "                #For test split\n",
    "                if param[\"num_test\"] > 0:\n",
    "                    random.seed(splitseed)\n",
    "                    list_graph, list_n_sequence, list_node_num, cent_mat, deg_mat = create_dataset(list_data[param[\"num_train\"]:param[\"num_train\"]+param[\"num_test\"]],num_copies = 1,adj_size=param[\"adj_size\"])\n",
    "\n",
    "                    with open(f\"./delivery/data_splits/test/{graph_file}_{genseed}_genseed_{param['num_test']}_test_{param['adj_size']}_size_{splitseed}_splitseed.pickle\",\"wb\") as fopen:\n",
    "                        pickle.dump([list_graph,list_n_sequence,list_node_num,cent_mat, deg_mat],fopen)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing synthetic graphs performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 graphs...\n",
      "Loading data...\n",
      "Processing 25 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.6433707281240552 and std: 0.07823708944609986\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.6848323000762395 and std: 0.0662049125692346\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.7433603418164613 and std: 0.06145596375996941\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.7836446000032846 and std: 0.06042670194897764\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.8020562728130729 and std: 0.06122871859264953\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.8115943377123658 and std: 0.06103639687297047\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.8188163937644557 and std: 0.060641768160102805\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.8243984219262295 and std: 0.06012270416232539\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.8289066029122886 and std: 0.059435875789000135\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.832408746333171 and std: 0.05850361826839651\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.8352315038201399 and std: 0.05791476721801093\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.8372868502587236 and std: 0.057577858571459556\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.8394103450808789 and std: 0.05710151509228987\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.8405211724846124 and std: 0.05689118851974327\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.8414413245204724 and std: 0.05696875481351833\n",
      "Processing 10 graphs...\n",
      "Loading data...\n",
      "Processing 25 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.9630341785812171 and std: 0.0027594629290967963\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.9641400078505906 and std: 0.002815597482205494\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.9659494093771055 and std: 0.00276632260893778\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.9678087227419436 and std: 0.002894154722757734\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.9692996543834662 and std: 0.003005685503847522\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.9706118946534072 and std: 0.0031708083880591428\n",
      "Epoch number: 7/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4d/f5lz4rj56ws3v2hlc19c60t80000gn/T/ipykernel_53428/2253922750.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch number: {e+1}/{num_epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_adj_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_adj_t_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_num_node_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbc_mat_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                         \u001b[0;31m#to check test loss while training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/tfm/tfm-GNN-Ranking/custom/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(list_adj_train, list_adj_t_train, list_num_node_train, bc_mat_train, model, device, optimizer, size)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " \n",
    "from model_bet import *\n",
    "import pandas as pd\n",
    "\n",
    "param = {\n",
    "    \"graph_files\": [\"ER_15_graphs_10000_5000_nodes\",\n",
    "                    \"SF_15_graphs_10000_5000_nodes\",\n",
    "                    \"GRP_15_graphs_10000_5000_nodes\"],\n",
    "\n",
    "    \"generation_seeds\": [10],\n",
    "    \"split_seeds\": [10],\n",
    "    \"num_copies\": [100],\n",
    "    \"adj_size\" : 10000,\n",
    "    \"num_train\" : 5,\n",
    "    \"num_test\" : 10,\n",
    "    \"model_seeds\": [15],\n",
    "    \"num_epochs\": 15,\n",
    "}\n",
    "\n",
    "Results = { \"gtype_train\":[],\n",
    "            \"generation_seed\":[],\n",
    "            \"splilt_seed\": [],\n",
    "            \"copies\":[],\n",
    "            \"adj_size\": [],\n",
    "            \"model_seed\": [],\n",
    "            \"epochs\": [],\n",
    "            \"kendalltau\":[],\n",
    "            \"std\":[]}\n",
    "\n",
    "for graph_file in param[\"graph_files\"]:\n",
    "    for genseed in param[\"generation_seeds\"]:\n",
    "        for splitseed in param[\"split_seeds\"]:\n",
    "            \n",
    "            test_file = f\"{graph_file}_{genseed}_genseed_{param['num_test']}_test_{param['adj_size']}_size_{splitseed}_splitseed.pickle\"\n",
    "            #Load test data\n",
    "            with open(\"./delivery/data_splits/test/\"+test_file,\"rb\") as fopen:\n",
    "                list_graph_test,list_n_seq_test,list_num_node_test,bc_mat_test,deg_mat_test = pickle.load(fopen)\n",
    "\n",
    "            list_adj_test,list_adj_t_test = graph_to_adj_bet(list_graph_test,list_n_seq_test,list_num_node_test,param['adj_size'])\n",
    "\n",
    "            for num_copies in param[\"num_copies\"]:\n",
    "\n",
    "                train_file = f\"{graph_file}_{genseed}_genseed_{param['num_train']}_train_{num_copies}_copies_{param['adj_size']}_size_{splitseed}_splitseed.pickle\"\n",
    "                #Load training data\n",
    "                print(f\"Loading data...\")\n",
    "                with open(\"./delivery/data_splits/train/\"+train_file,\"rb\") as fopen:\n",
    "                    list_graph_train,list_n_seq_train,list_num_node_train,bc_mat_train,deg_mat_train = pickle.load(fopen)\n",
    "\n",
    "                model_size = bc_mat_train.shape[0]\n",
    "                assert model_size == param['adj_size']\n",
    "                \n",
    "                list_adj_train,list_adj_t_train = graph_to_adj_bet(list_graph_train,list_n_seq_train,list_num_node_train,param['adj_size'])\n",
    "                \n",
    "                for model_seed in param[\"model_seeds\"]:\n",
    "                    #Model parameters\n",
    "\n",
    "                    torch.manual_seed(model_seed)\n",
    "                    \n",
    "                    hidden = 20\n",
    "                    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                    model = GNN_Bet(ninput=model_size,nhid=hidden,dropout=0.6)\n",
    "                    model.to(device)\n",
    "\n",
    "                    optimizer = torch.optim.Adam(model.parameters(),lr=0.0005)\n",
    "                    num_epoch = param[\"num_epochs\"]\n",
    "\n",
    "                    print(f\"Training, total Number of epoches: {num_epoch}\")\n",
    "                    for e in range(num_epoch):\n",
    "                        print(f\"Epoch number: {e+1}/{num_epoch}\")\n",
    "                        train(list_adj_train,list_adj_t_train,list_num_node_train,bc_mat_train,model,device,optimizer,model_size)\n",
    "\n",
    "                        #to check test loss while training\n",
    "                        with torch.no_grad():\n",
    "                            r = test(list_adj_test,list_adj_t_test,list_num_node_test,bc_mat_test,deg_mat_test,model,device,model_size)\n",
    "\n",
    "                        Results[\"gtype_train\"].append(train_file)\n",
    "                        Results[\"generation_seed\"].append(genseed)\n",
    "                        Results[\"splilt_seed\"].append(splitseed)\n",
    "                        Results[\"copies\"].append(num_copies)\n",
    "                        Results[\"adj_size\"].append(model_size)\n",
    "                        Results[\"model_seed\"].append(model_seed)\n",
    "                        Results[\"epochs\"].append(e)\n",
    "                        Results[\"kendalltau\"].append(r[\"kt\"])\n",
    "                        Results[\"std\"].append(r[\"std\"])\n",
    "\n",
    "                        df = pd.DataFrame.from_dict(Results)\n",
    "                        #df.to_csv(\"output_synthetic_graphs_performance.csv\")\n",
    "                        df.to_csv(\"./delivery/output_synthetic_graphs_performance_exp1.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets varying replication parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"adj_size\" : 10000,\n",
    "    \"num_train\" : 5,\n",
    "    \"num_test\" : 10,\n",
    "    \"num_copies\": [1,2,10,20,40],\n",
    "    \"graph_files\": [\"ER_15_graphs_10000_5000_nodes\",\n",
    "                    \"SF_15_graphs_10000_5000_nodes\",\n",
    "                    \"GRP_15_graphs_10000_5000_nodes\"],\n",
    "    \"split_seeds\": [10],\n",
    "    \"generation_seeds\": [10]\n",
    "}\n",
    "\n",
    "\n",
    "for graph_file in param[\"graph_files\"]:\n",
    "    for genseed in param[\"generation_seeds\"]:\n",
    "        for num_copies in param[\"num_copies\"]:\n",
    "            for splitseed in param[\"split_seeds\"]:\n",
    "        \n",
    "                with open(f\"./delivery/graphs/{graph_file}_{genseed}_genseed.pickle\",\"rb\") as fopen:\n",
    "                    list_data = pickle.load(fopen)\n",
    "\n",
    "                num_graph = len(list_data)\n",
    "                assert param[\"num_train\"]+param[\"num_test\"] == num_graph,\"Required split size doesn't match number of graphs in pickle file.\"\n",
    "            \n",
    "                #For training split\n",
    "                if param[\"num_train\"] > 0:\n",
    "                    random.seed(splitseed)\n",
    "                    list_graph, list_n_sequence, list_node_num, cent_mat, deg_mat = create_dataset(list_data[:param[\"num_train\"]],num_copies = num_copies, adj_size=param[\"adj_size\"])\n",
    "\n",
    "                    with open(f\"./delivery/data_splits/train/{graph_file}_{genseed}_genseed_{param['num_train']}_train_{num_copies}_copies_{param['adj_size']}_size_{splitseed}_splitseed.pickle\",\"wb\") as fopen:\n",
    "                        pickle.dump([list_graph,list_n_sequence,list_node_num,cent_mat, deg_mat],fopen)\n",
    "\n",
    "                #For test split\n",
    "                if param[\"num_test\"] > 0:\n",
    "                    random.seed(splitseed)\n",
    "                    list_graph, list_n_sequence, list_node_num, cent_mat, deg_mat = create_dataset(list_data[param[\"num_train\"]:param[\"num_train\"]+param[\"num_test\"]],num_copies = 1,adj_size=param[\"adj_size\"])\n",
    "\n",
    "                    with open(f\"./delivery/data_splits/test/{graph_file}_{genseed}_genseed_{param['num_test']}_test_{param['adj_size']}_size_{splitseed}_splitseed.pickle\",\"wb\") as fopen:\n",
    "                        pickle.dump([list_graph,list_n_sequence,list_node_num,cent_mat, deg_mat],fopen)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing performance when varying the replication parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 graphs...\n",
      "Loading data...\n",
      "Processing 25 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.6433707281240552 and std: 0.07823708944609986\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.6848323000762395 and std: 0.0662049125692346\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.7433603418164613 and std: 0.06145596375996941\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.7836446000032846 and std: 0.06042670194897764\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.8020562728130729 and std: 0.06122871859264953\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.8115943377123658 and std: 0.06103639687297047\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.8188163937644557 and std: 0.060641768160102805\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.8243984219262295 and std: 0.06012270416232539\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.8289066029122886 and std: 0.059435875789000135\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.832408746333171 and std: 0.05850361826839651\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.8352315038201399 and std: 0.05791476721801093\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.8372868502587236 and std: 0.057577858571459556\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.8394103450808789 and std: 0.05710151509228987\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.8405211724846124 and std: 0.05689118851974327\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.8414413245204724 and std: 0.05696875481351833\n",
      "Processing 10 graphs...\n",
      "Loading data...\n",
      "Processing 25 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.9630341785812171 and std: 0.0027594629290967963\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.9641400078505906 and std: 0.002815597482205494\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.9659494093771055 and std: 0.00276632260893778\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.9678087227419436 and std: 0.002894154722757734\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.9692996543834662 and std: 0.003005685503847522\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.9706118946534072 and std: 0.0031708083880591428\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.971492111380772 and std: 0.0032011438550025697\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.9721456193567981 and std: 0.003191363547966186\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.9726820009449147 and std: 0.0032544441101596123\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.973036930374761 and std: 0.0033135267613749668\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.9733512144332226 and std: 0.003311344623840223\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.9735715231207556 and std: 0.0033808124358865443\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.9736484376088532 and std: 0.003393127653303618\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.9736704347305224 and std: 0.0034236070620916595\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.973757259858697 and std: 0.003410548565833143\n",
      "Processing 10 graphs...\n",
      "Loading data...\n",
      "Processing 25 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.7068774307462828 and std: 0.09255975824678793\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.7559573369650174 and std: 0.07872454731700859\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.8127239263501332 and std: 0.06983058534514476\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.8409635104344109 and std: 0.06334268891998121\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.8518079993403231 and std: 0.060065160848654535\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.8589678050037021 and std: 0.057693275523651444\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.8644283686421147 and std: 0.0555006646972487\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.8683940394470178 and std: 0.05399240304461916\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.8712242482056686 and std: 0.053185532599064965\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.8734476179921431 and std: 0.05255658847407811\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.8754036151241891 and std: 0.05238057860781526\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.8770491530304664 and std: 0.052200984699788705\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.8780759182199563 and std: 0.05219935086633813\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.8789687780634164 and std: 0.052306375858266405\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.8798244128319865 and std: 0.05211638374974802\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from model_bet import *\n",
    "import pandas as pd\n",
    "\n",
    "param = {\n",
    "    \"graph_files\": [\"ER_15_graphs_10000_5000_nodes\",\n",
    "                    \"SF_15_graphs_10000_5000_nodes\",\n",
    "                    \"GRP_15_graphs_10000_5000_nodes\"],\n",
    "\n",
    "    \"generation_seeds\": [10],\n",
    "    \"split_seeds\": [10],\n",
    "    \"num_copies\": [1,2,10,20,40],\n",
    "    \"adj_size\" : 10000,\n",
    "    \"num_train\" : 5,\n",
    "    \"num_test\" : 10,\n",
    "    \"model_seeds\": [15],\n",
    "    \"num_epochs\": 15,\n",
    "}\n",
    "\n",
    "Results = { \"gtype_train\":[],\n",
    "            \"generation_seed\":[],\n",
    "            \"splilt_seed\": [],\n",
    "            \"copies\":[],\n",
    "            \"adj_size\": [],\n",
    "            \"model_seed\": [],\n",
    "            \"epochs\": [],\n",
    "            \"kendalltau\":[],\n",
    "            \"std\":[]}\n",
    "\n",
    "for graph_file in param[\"graph_files\"]:\n",
    "    for genseed in param[\"generation_seeds\"]:\n",
    "        for splitseed in param[\"split_seeds\"]:\n",
    "            \n",
    "            test_file = f\"{graph_file}_{genseed}_genseed_{param['num_test']}_test_{param['adj_size']}_size_{splitseed}_splitseed.pickle\"\n",
    "            #Load test data\n",
    "            with open(\"./delivery/data_splits/test/\"+test_file,\"rb\") as fopen:\n",
    "                list_graph_test,list_n_seq_test,list_num_node_test,bc_mat_test,deg_mat_test = pickle.load(fopen)\n",
    "\n",
    "            list_adj_test,list_adj_t_test = graph_to_adj_bet(list_graph_test,list_n_seq_test,list_num_node_test,param['adj_size'])\n",
    "\n",
    "            for num_copies in param[\"num_copies\"]:\n",
    "\n",
    "                train_file = f\"{graph_file}_{genseed}_genseed_{param['num_train']}_train_{num_copies}_copies_{param['adj_size']}_size_{splitseed}_splitseed.pickle\"\n",
    "                #Load training data\n",
    "                print(f\"Loading data...\")\n",
    "                with open(\"./delivery/data_splits/train/\"+train_file,\"rb\") as fopen:\n",
    "                    list_graph_train,list_n_seq_train,list_num_node_train,bc_mat_train,deg_mat_train = pickle.load(fopen)\n",
    "\n",
    "                model_size = bc_mat_train.shape[0]\n",
    "                assert model_size == param['adj_size']\n",
    "                \n",
    "                list_adj_train,list_adj_t_train = graph_to_adj_bet(list_graph_train,list_n_seq_train,list_num_node_train,param['adj_size'])\n",
    "                \n",
    "                for model_seed in param[\"model_seeds\"]:\n",
    "                    #Model parameters\n",
    "\n",
    "                    torch.manual_seed(model_seed)\n",
    "                    \n",
    "                    hidden = 20\n",
    "                    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                    model = GNN_Bet(ninput=model_size,nhid=hidden,dropout=0.6)\n",
    "                    model.to(device)\n",
    "\n",
    "                    optimizer = torch.optim.Adam(model.parameters(),lr=0.0005)\n",
    "                    num_epoch = param[\"num_epochs\"]\n",
    "\n",
    "                    print(f\"Training, total Number of epoches: {num_epoch}\")\n",
    "                    for e in range(num_epoch):\n",
    "                        print(f\"Epoch number: {e+1}/{num_epoch}\")\n",
    "                        train(list_adj_train,list_adj_t_train,list_num_node_train,bc_mat_train,model,device,optimizer,model_size)\n",
    "\n",
    "                        #to check test loss while training\n",
    "                        with torch.no_grad():\n",
    "                            r = test(list_adj_test,list_adj_t_test,list_num_node_test,bc_mat_test,deg_mat_test,model,device,model_size)\n",
    "\n",
    "                        Results[\"gtype_train\"].append(train_file)\n",
    "                        Results[\"generation_seed\"].append(genseed)\n",
    "                        Results[\"splilt_seed\"].append(splitseed)\n",
    "                        Results[\"copies\"].append(num_copies)\n",
    "                        Results[\"adj_size\"].append(model_size)\n",
    "                        Results[\"model_seed\"].append(model_seed)\n",
    "                        Results[\"epochs\"].append(e)\n",
    "                        Results[\"kendalltau\"].append(r[\"kt\"])\n",
    "                        Results[\"std\"].append(r[\"std\"])\n",
    "\n",
    "                        df = pd.DataFrame.from_dict(Results)\n",
    "                        df.to_csv(\"./delivery/output_synthetic_graphs_performance_exp2.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We generate a set of 10 synthetic graphs for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10 ER graphs\n",
      "26/04/2023 16:40:22: Graph index:1/10\n",
      "26/04/2023 16:40:22: Graph index:2/10\n",
      "26/04/2023 16:40:22: Graph index:3/10\n",
      "26/04/2023 16:40:22: Graph index:4/10\n",
      "26/04/2023 16:40:22: Graph index:5/10\n",
      "26/04/2023 16:40:22: Graph index:6/10\n",
      "26/04/2023 16:40:22: Graph index:7/10\n",
      "26/04/2023 16:40:23: Graph index:8/10\n",
      "26/04/2023 16:40:23: Graph index:9/10\n",
      "26/04/2023 16:40:23: Graph index:10/10\n",
      "Generating 10 SF graphs\n",
      "26/04/2023 16:40:23: Graph index:1/10\n",
      "26/04/2023 16:40:24: Graph index:2/10\n",
      "26/04/2023 16:40:24: Graph index:3/10\n",
      "26/04/2023 16:40:25: Graph index:4/10\n",
      "26/04/2023 16:40:26: Graph index:5/10\n",
      "26/04/2023 16:40:26: Graph index:6/10\n",
      "26/04/2023 16:40:27: Graph index:7/10\n",
      "26/04/2023 16:40:28: Graph index:8/10\n",
      "26/04/2023 16:40:29: Graph index:9/10\n",
      "26/04/2023 16:40:30: Graph index:10/10\n",
      "Generating 10 GRP graphs\n",
      "26/04/2023 16:40:30: Graph index:1/10\n",
      "26/04/2023 16:40:31: Graph index:2/10\n",
      "26/04/2023 16:40:31: Graph index:3/10\n",
      "26/04/2023 16:40:31: Graph index:4/10\n",
      "26/04/2023 16:40:32: Graph index:5/10\n",
      "26/04/2023 16:40:32: Graph index:6/10\n",
      "26/04/2023 16:40:32: Graph index:7/10\n",
      "26/04/2023 16:40:33: Graph index:8/10\n",
      "26/04/2023 16:40:33: Graph index:9/10\n",
      "26/04/2023 16:40:33: Graph index:10/10\n",
      "Graphs saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "param = {\n",
    "    \"min_nodes\": 1000,#5000,\n",
    "    \"max_nodes\": 2000,#10000,\n",
    "    \"num_of_graphs\": 10,\n",
    "    \"graph_types\": [\"ER\",\"SF\",\"GRP\"],\n",
    "    \"generation_seeds\": [10]\n",
    "}\n",
    "\n",
    "for graph_type in param[\"graph_types\"]:\n",
    "\n",
    "    for seed in param[\"generation_seeds\"]:\n",
    "        \n",
    "        random.seed(seed)\n",
    "\n",
    "        print(f\"Generating {param['num_of_graphs']} {graph_type} graphs\")\n",
    "        list_bet_data = list()\n",
    "        for i in range(param['num_of_graphs']):\n",
    "            print(f\"{datetime.now().strftime('%d/%m/%Y %H:%M:%S')}: Graph index:{i+1}/{param['num_of_graphs']}\")\n",
    "            g_nx = create_graph(graph_type,param['min_nodes'],param['max_nodes'])\n",
    "            \n",
    "            if nx.number_of_isolates(g_nx)>0:\n",
    "                g_nx.remove_nodes_from(list(nx.isolates(g_nx)))\n",
    "                g_nx = nx.convert_node_labels_to_integers(g_nx)\n",
    "\n",
    "            g_nkit = nx2nkit(g_nx)\n",
    "            bet_dict = cal_exact_bet(g_nkit)\n",
    "            deg_dict = cal_exact_degree(g_nkit)\n",
    "            list_bet_data.append([g_nx,bet_dict,deg_dict])\n",
    "\n",
    "        fname_bet = f\"./delivery/graphs/{graph_type}_{param['num_of_graphs']}_graphs_{param['max_nodes']}_{param['min_nodes']}_nodes_{seed}_genseed.pickle\"    \n",
    "\n",
    "        with open(fname_bet,\"wb\") as fopen:\n",
    "            pickle.dump(list_bet_data,fopen)\n",
    "\n",
    "print(\"Graphs saved\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We generate a set of 5 synthetic training graphs for training using different random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5 ER graphs\n",
      "26/04/2023 16:40:37: Graph index:1/5\n",
      "26/04/2023 16:40:38: Graph index:2/5\n",
      "26/04/2023 16:40:38: Graph index:3/5\n",
      "26/04/2023 16:40:38: Graph index:4/5\n",
      "26/04/2023 16:40:38: Graph index:5/5\n",
      "Generating 5 ER graphs\n",
      "26/04/2023 16:40:39: Graph index:1/5\n",
      "26/04/2023 16:40:39: Graph index:2/5\n",
      "26/04/2023 16:40:39: Graph index:3/5\n",
      "26/04/2023 16:40:39: Graph index:4/5\n",
      "26/04/2023 16:40:39: Graph index:5/5\n",
      "Generating 5 ER graphs\n",
      "26/04/2023 16:40:39: Graph index:1/5\n",
      "26/04/2023 16:40:39: Graph index:2/5\n",
      "26/04/2023 16:40:39: Graph index:3/5\n",
      "26/04/2023 16:40:39: Graph index:4/5\n",
      "26/04/2023 16:40:40: Graph index:5/5\n",
      "Generating 5 ER graphs\n",
      "26/04/2023 16:40:40: Graph index:1/5\n",
      "26/04/2023 16:40:40: Graph index:2/5\n",
      "26/04/2023 16:40:40: Graph index:3/5\n",
      "26/04/2023 16:40:40: Graph index:4/5\n",
      "26/04/2023 16:40:40: Graph index:5/5\n",
      "Generating 5 ER graphs\n",
      "26/04/2023 16:40:40: Graph index:1/5\n",
      "26/04/2023 16:40:41: Graph index:2/5\n",
      "26/04/2023 16:40:41: Graph index:3/5\n",
      "26/04/2023 16:40:41: Graph index:4/5\n",
      "26/04/2023 16:40:41: Graph index:5/5\n",
      "Generating 5 SF graphs\n",
      "26/04/2023 16:40:41: Graph index:1/5\n",
      "26/04/2023 16:40:42: Graph index:2/5\n",
      "26/04/2023 16:40:43: Graph index:3/5\n",
      "26/04/2023 16:40:44: Graph index:4/5\n",
      "26/04/2023 16:40:45: Graph index:5/5\n",
      "Generating 5 SF graphs\n",
      "26/04/2023 16:40:46: Graph index:1/5\n",
      "26/04/2023 16:40:46: Graph index:2/5\n",
      "26/04/2023 16:40:47: Graph index:3/5\n",
      "26/04/2023 16:40:48: Graph index:4/5\n",
      "26/04/2023 16:40:49: Graph index:5/5\n",
      "Generating 5 SF graphs\n",
      "26/04/2023 16:40:50: Graph index:1/5\n",
      "26/04/2023 16:40:50: Graph index:2/5\n",
      "26/04/2023 16:40:51: Graph index:3/5\n",
      "26/04/2023 16:40:52: Graph index:4/5\n",
      "26/04/2023 16:40:52: Graph index:5/5\n",
      "Generating 5 SF graphs\n",
      "26/04/2023 16:40:53: Graph index:1/5\n",
      "26/04/2023 16:40:54: Graph index:2/5\n",
      "26/04/2023 16:40:55: Graph index:3/5\n",
      "26/04/2023 16:40:55: Graph index:4/5\n",
      "26/04/2023 16:40:56: Graph index:5/5\n",
      "Generating 5 SF graphs\n",
      "26/04/2023 16:40:56: Graph index:1/5\n",
      "26/04/2023 16:40:57: Graph index:2/5\n",
      "26/04/2023 16:40:58: Graph index:3/5\n",
      "26/04/2023 16:40:59: Graph index:4/5\n",
      "26/04/2023 16:40:59: Graph index:5/5\n",
      "Generating 5 GRP graphs\n",
      "26/04/2023 16:41:00: Graph index:1/5\n",
      "26/04/2023 16:41:00: Graph index:2/5\n",
      "26/04/2023 16:41:00: Graph index:3/5\n",
      "26/04/2023 16:41:01: Graph index:4/5\n",
      "26/04/2023 16:41:01: Graph index:5/5\n",
      "Generating 5 GRP graphs\n",
      "26/04/2023 16:41:01: Graph index:1/5\n",
      "26/04/2023 16:41:02: Graph index:2/5\n",
      "26/04/2023 16:41:02: Graph index:3/5\n",
      "26/04/2023 16:41:02: Graph index:4/5\n",
      "26/04/2023 16:41:02: Graph index:5/5\n",
      "Generating 5 GRP graphs\n",
      "26/04/2023 16:41:03: Graph index:1/5\n",
      "26/04/2023 16:41:04: Graph index:2/5\n",
      "26/04/2023 16:41:04: Graph index:3/5\n",
      "26/04/2023 16:41:04: Graph index:4/5\n",
      "26/04/2023 16:41:05: Graph index:5/5\n",
      "Generating 5 GRP graphs\n",
      "26/04/2023 16:41:05: Graph index:1/5\n",
      "26/04/2023 16:41:06: Graph index:2/5\n",
      "26/04/2023 16:41:06: Graph index:3/5\n",
      "26/04/2023 16:41:06: Graph index:4/5\n",
      "26/04/2023 16:41:06: Graph index:5/5\n",
      "Generating 5 GRP graphs\n",
      "26/04/2023 16:41:07: Graph index:1/5\n",
      "26/04/2023 16:41:07: Graph index:2/5\n",
      "26/04/2023 16:41:08: Graph index:3/5\n",
      "26/04/2023 16:41:08: Graph index:4/5\n",
      "26/04/2023 16:41:08: Graph index:5/5\n",
      "Graphs saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "param = {\n",
    "    \"min_nodes\": 1000,#5000,\n",
    "    \"max_nodes\": 2000,#10000,\n",
    "    \"num_of_graphs\": 5,\n",
    "    \"graph_types\": [\"ER\",\"SF\",\"GRP\"],\n",
    "    \"generation_seeds\": [j for j in range(5)]\n",
    "}\n",
    "\n",
    "for graph_type in param[\"graph_types\"]:\n",
    "\n",
    "    for seed in param[\"generation_seeds\"]:\n",
    "        \n",
    "        #random.seed(seed)\n",
    "\n",
    "        print(f\"Generating {param['num_of_graphs']} {graph_type} graphs\")\n",
    "        list_bet_data = list()\n",
    "        for i in range(param['num_of_graphs']):\n",
    "            print(f\"{datetime.now().strftime('%d/%m/%Y %H:%M:%S')}: Graph index:{i+1}/{param['num_of_graphs']}\")\n",
    "            g_nx = create_graph(graph_type,param['min_nodes'],param['max_nodes'])\n",
    "            \n",
    "            if nx.number_of_isolates(g_nx)>0:\n",
    "                g_nx.remove_nodes_from(list(nx.isolates(g_nx)))\n",
    "                g_nx = nx.convert_node_labels_to_integers(g_nx)\n",
    "\n",
    "            g_nkit = nx2nkit(g_nx)\n",
    "            bet_dict = cal_exact_bet(g_nkit)\n",
    "            deg_dict = cal_exact_degree(g_nkit)\n",
    "            list_bet_data.append([g_nx,bet_dict,deg_dict])\n",
    "\n",
    "        fname_bet = f\"./delivery/graphs/{graph_type}_{param['num_of_graphs']}_graphs_{param['max_nodes']}_{param['min_nodes']}_nodes_{seed}_genseed.pickle\"    \n",
    "\n",
    "        with open(fname_bet,\"wb\") as fopen:\n",
    "            pickle.dump(list_bet_data,fopen)\n",
    "\n",
    "print(\"Graphs saved\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We generate the test splilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"adj_size\" : 10000,\n",
    "    \"num_train\" : 0,\n",
    "    \"num_test\" : 10,\n",
    "    \"num_copies\": [10],\n",
    "    \"graph_files\": [\"ER_10_graphs_2000_1000_nodes\",\n",
    "                    \"SF_10_graphs_2000_1000_nodes\",\n",
    "                    \"GRP_10_graphs_2000_1000_nodes\"],\n",
    "    \"split_seeds\": [0],\n",
    "    \"generation_seeds\": [10]\n",
    "}\n",
    "\n",
    "\n",
    "for graph_file in param[\"graph_files\"]:\n",
    "    for genseed in param[\"generation_seeds\"]:\n",
    "        for num_copies in param[\"num_copies\"]:\n",
    "            for splitseed in param[\"split_seeds\"]:\n",
    "        \n",
    "                with open(f\"./delivery/graphs/{graph_file}_{genseed}_genseed.pickle\",\"rb\") as fopen:\n",
    "                    list_data = pickle.load(fopen)\n",
    "\n",
    "                num_graph = len(list_data)\n",
    "                assert param[\"num_train\"]+param[\"num_test\"] == num_graph,\"Required split size doesn't match number of graphs in pickle file.\"\n",
    "            \n",
    "                #For training split\n",
    "                if param[\"num_train\"] > 0:\n",
    "                    random.seed(splitseed)\n",
    "                    list_graph, list_n_sequence, list_node_num, cent_mat, deg_mat = create_dataset(list_data[:param[\"num_train\"]],num_copies = num_copies, adj_size=param[\"adj_size\"])\n",
    "\n",
    "                    with open(f\"./delivery/data_splits/train/{graph_file}_{genseed}_genseed_{param['num_train']}_train_{num_copies}_copies_{param['adj_size']}_size_{splitseed}_splitseed.pickle\",\"wb\") as fopen:\n",
    "                        pickle.dump([list_graph,list_n_sequence,list_node_num,cent_mat, deg_mat],fopen)\n",
    "\n",
    "                #For test split\n",
    "                if param[\"num_test\"] > 0:\n",
    "                    random.seed(splitseed)\n",
    "                    list_graph, list_n_sequence, list_node_num, cent_mat, deg_mat = create_dataset(list_data[param[\"num_train\"]:param[\"num_train\"]+param[\"num_test\"]],num_copies = 1,adj_size=param[\"adj_size\"])\n",
    "\n",
    "                    with open(f\"./delivery/data_splits/test/{graph_file}_{genseed}_genseed_{param['num_test']}_test_{param['adj_size']}_size_{splitseed}_splitseed.pickle\",\"wb\") as fopen:\n",
    "                        pickle.dump([list_graph,list_n_sequence,list_node_num,cent_mat, deg_mat],fopen)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We generate the splits for the training sets with different random seed generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"adj_size\" : 10000,\n",
    "    \"num_train\" : 5,\n",
    "    \"num_test\" : 0,\n",
    "    \"num_copies\": [10],\n",
    "    \"graph_files\": [\"ER_5_graphs_2000_1000_nodes\",\n",
    "                    \"SF_5_graphs_2000_1000_nodes\",\n",
    "                    \"GRP_5_graphs_2000_1000_nodes\"],\n",
    "    \"split_seeds\": [j for j in range(5)],\n",
    "    \"generation_seeds\": [0]\n",
    "}\n",
    "\n",
    "\n",
    "for graph_file in param[\"graph_files\"]:\n",
    "    for genseed in param[\"generation_seeds\"]:\n",
    "        for num_copies in param[\"num_copies\"]:\n",
    "            for splitseed in param[\"split_seeds\"]:\n",
    "        \n",
    "                with open(f\"./delivery/graphs/{graph_file}_{genseed}_genseed.pickle\",\"rb\") as fopen:\n",
    "                    list_data = pickle.load(fopen)\n",
    "\n",
    "                num_graph = len(list_data)\n",
    "                assert param[\"num_train\"]+param[\"num_test\"] == num_graph,\"Required split size doesn't match number of graphs in pickle file.\"\n",
    "            \n",
    "                #For training split\n",
    "                if param[\"num_train\"] > 0:\n",
    "                    random.seed(splitseed)\n",
    "                    list_graph, list_n_sequence, list_node_num, cent_mat, deg_mat = create_dataset(list_data[:param[\"num_train\"]],num_copies = num_copies, adj_size=param[\"adj_size\"])\n",
    "\n",
    "                    with open(f\"./delivery/data_splits/train/{graph_file}_{genseed}_genseed_{param['num_train']}_train_{num_copies}_copies_{param['adj_size']}_size_{splitseed}_splitseed.pickle\",\"wb\") as fopen:\n",
    "                        pickle.dump([list_graph,list_n_sequence,list_node_num,cent_mat, deg_mat],fopen)\n",
    "\n",
    "                #For test split\n",
    "                if param[\"num_test\"] > 0:\n",
    "                    random.seed(splitseed)\n",
    "                    list_graph, list_n_sequence, list_node_num, cent_mat, deg_mat = create_dataset(list_data[param[\"num_train\"]:param[\"num_train\"]+param[\"num_test\"]],num_copies = 1,adj_size=param[\"adj_size\"])\n",
    "\n",
    "                    with open(f\"./delivery/data_splits/test/{graph_file}_{genseed}_genseed_{param['num_test']}_test_{param['adj_size']}_size_{splitseed}_splitseed.pickle\",\"wb\") as fopen:\n",
    "                        pickle.dump([list_graph,list_n_sequence,list_node_num,cent_mat, deg_mat],fopen)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We train and test using the diferent graphs created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"adj_size\" : 10000,\n",
    "    \"num_train\" : 5,\n",
    "    \"num_test\" : 0,\n",
    "    \"num_copies\": [10],\n",
    "    \"graph_files\": [\"ER_5_graphs_2000_1000_nodes\",\n",
    "                    \"SF_5_graphs_2000_1000_nodes\",\n",
    "                    \"GRP_5_graphs_2000_1000_nodes\"],\n",
    "    \"split_seeds\": [0],\n",
    "    \"generation_seeds\": [j for j in range(5)]\n",
    "}\n",
    "\n",
    "\n",
    "for graph_file in param[\"graph_files\"]:\n",
    "    for genseed in param[\"generation_seeds\"]:\n",
    "        for num_copies in param[\"num_copies\"]:\n",
    "            for splitseed in param[\"split_seeds\"]:\n",
    "        \n",
    "                with open(f\"./delivery/graphs/{graph_file}_{genseed}_genseed.pickle\",\"rb\") as fopen:\n",
    "                    list_data = pickle.load(fopen)\n",
    "\n",
    "                num_graph = len(list_data)\n",
    "                assert param[\"num_train\"]+param[\"num_test\"] == num_graph,\"Required split size doesn't match number of graphs in pickle file.\"\n",
    "            \n",
    "                #For training split\n",
    "                if param[\"num_train\"] > 0:\n",
    "                    random.seed(splitseed)\n",
    "                    list_graph, list_n_sequence, list_node_num, cent_mat, deg_mat = create_dataset(list_data[:param[\"num_train\"]],num_copies = num_copies, adj_size=param[\"adj_size\"])\n",
    "\n",
    "                    with open(f\"./delivery/data_splits/train/{graph_file}_{genseed}_genseed_{param['num_train']}_train_{num_copies}_copies_{param['adj_size']}_size_{splitseed}_splitseed.pickle\",\"wb\") as fopen:\n",
    "                        pickle.dump([list_graph,list_n_sequence,list_node_num,cent_mat, deg_mat],fopen)\n",
    "\n",
    "                #For test split\n",
    "                if param[\"num_test\"] > 0:\n",
    "                    random.seed(splitseed)\n",
    "                    list_graph, list_n_sequence, list_node_num, cent_mat, deg_mat = create_dataset(list_data[param[\"num_train\"]:param[\"num_train\"]+param[\"num_test\"]],num_copies = 1,adj_size=param[\"adj_size\"])\n",
    "\n",
    "                    with open(f\"./delivery/data_splits/test/{graph_file}_{genseed}_genseed_{param['num_test']}_test_{param['adj_size']}_size_{splitseed}_splitseed.pickle\",\"wb\") as fopen:\n",
    "                        pickle.dump([list_graph,list_n_sequence,list_node_num,cent_mat, deg_mat],fopen)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We train and test using the different graph created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 graphs...\n",
      "Loading data...\n",
      "Processing 50 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.7467893824796327 and std: 0.07645942572944546\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.8131740429052442 and std: 0.05670450560938412\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.834524012195136 and std: 0.055753792869293536\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.8453164649658869 and std: 0.05352057238808083\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.8539757671010759 and std: 0.052870334949941575\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.8602889009741974 and std: 0.0524043557951551\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.8650949217734029 and std: 0.05220560815431934\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.8690275935563163 and std: 0.05249874241607539\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.8716678729166178 and std: 0.052609458890178776\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.873777543570213 and std: 0.05266485529889514\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.8749900339520768 and std: 0.052483923869005494\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.8757165122388036 and std: 0.05224056134336259\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.876649791758366 and std: 0.05235488479645609\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.8770896151256625 and std: 0.05248543625345772\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.8777709463839471 and std: 0.052563427685066284\n",
      "Loading data...\n",
      "Processing 50 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.7205474025563581 and std: 0.08362840622842861\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.8106300722621878 and std: 0.0763810965711912\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.8336159173916643 and std: 0.07161527368002149\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.8444397344120921 and std: 0.06817231582127657\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.8528546605885943 and std: 0.06456365481342517\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.8586631013979863 and std: 0.06256792372203221\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.8633596481093934 and std: 0.061284024031697894\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.8665638877684476 and std: 0.060297542542715535\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.8691639478503284 and std: 0.05955932241525543\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.8713012738836599 and std: 0.05916567918887452\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.8728928902314438 and std: 0.059019090101982384\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.8743393708270851 and std: 0.05881876720337748\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.8748796183503081 and std: 0.05866207004615414\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.8753746706626483 and std: 0.05853816278867136\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.8753801798498625 and std: 0.05864345114006564\n",
      "Loading data...\n",
      "Processing 50 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.7125293727146431 and std: 0.08013620200805148\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.8059130097168452 and std: 0.07252221154079849\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.8309035166049628 and std: 0.06880401574208488\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.8423959048319689 and std: 0.0658159094683081\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.8496877486255915 and std: 0.06336919035369101\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.8552462406267693 and std: 0.061899156073966635\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.8591382023845113 and std: 0.06053532342995663\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.8620740211059486 and std: 0.05943639747544522\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.864100959387512 and std: 0.05887992235322717\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.8654588243559729 and std: 0.05827695679983464\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.8663153088051809 and std: 0.058069453216579595\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.8670747798294226 and std: 0.057907780085023425\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.867272405908652 and std: 0.057872495540557505\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.8674200681694924 and std: 0.057725404731554374\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.8674600704939003 and std: 0.05771632874585966\n",
      "Loading data...\n",
      "Processing 50 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.7323699714451486 and std: 0.08038332925239886\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.8163502243535561 and std: 0.06774935206530498\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.8351151793760792 and std: 0.0640721214452125\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.8457432343736052 and std: 0.06144564809959687\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.8536334750300814 and std: 0.06012099330683984\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.8586290278025144 and std: 0.058756318186548605\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.8623333217160984 and std: 0.05778341111048972\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.8650187518496221 and std: 0.05706316931411115\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.8669867989817236 and std: 0.05653128613193676\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.86826667283996 and std: 0.05617815056413104\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.8694139324428125 and std: 0.05641471413675236\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.8701994478271293 and std: 0.05650021050195679\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.8705769419492653 and std: 0.05643420026709936\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.8707816730034038 and std: 0.05679543929834669\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.8716007253137972 and std: 0.05703798024540244\n",
      "Loading data...\n",
      "Processing 50 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.7226992969737995 and std: 0.07550885185311139\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.8019219044331942 and std: 0.06272789361088796\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.8237707795805352 and std: 0.06066523310746233\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.8364521523651722 and std: 0.05979830760412654\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.844599143952389 and std: 0.05884354585332287\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.8502524145950039 and std: 0.05780172718419733\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.8547027231745605 and std: 0.056491394582873\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.8579665540876185 and std: 0.055815366165456265\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.8607581730487877 and std: 0.05525268608919417\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.8628500595695426 and std: 0.05492736856413992\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.8646704661299806 and std: 0.054850249848806557\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.8658381197906726 and std: 0.054712654029605574\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.8670106641419357 and std: 0.0548336498603281\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.8686246309151983 and std: 0.05505319447188353\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.8692143679284354 and std: 0.05522033815476477\n",
      "Loading data...\n",
      "Processing 50 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.6705130910259778 and std: 0.09244969021656536\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.6995518664967602 and std: 0.09666998040104961\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.7247364248190434 and std: 0.10230657508249953\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.7411832619813484 and std: 0.10930219576219732\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.7484555267628372 and std: 0.11509920828820284\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.7524879870929005 and std: 0.12067346185733067\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.7537359545300552 and std: 0.12485821434058914\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.7519302054053375 and std: 0.1321830252168702\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.7527487167017737 and std: 0.13623635090130065\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.7550161256790097 and std: 0.1375708115058386\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.7502808680218875 and std: 0.1459620790899607\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.7540360104042788 and std: 0.14319043672548648\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.7425057495687173 and std: 0.15674192103876716\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.7443890683117595 and std: 0.15593759371590407\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.7399038591828505 and std: 0.16190554325267018\n",
      "Loading data...\n",
      "Processing 50 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.6745482072674649 and std: 0.09099414065676303\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.7074648132407788 and std: 0.09613687093379174\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.7327064914669901 and std: 0.10433640916989297\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.7470364758766925 and std: 0.113536293714245\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.7548503270019218 and std: 0.11794207002550097\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.7644821030000987 and std: 0.11644853754562882\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.7715621773645935 and std: 0.11444195229408172\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.7736731622043944 and std: 0.11677238859634802\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.77755886676628 and std: 0.11420364870398146\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.7775943805690038 and std: 0.11648412301944806\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.7738677640978555 and std: 0.12229430324742412\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.7729524973021854 and std: 0.12256641501838168\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.76504529438456 and std: 0.1328194055787391\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.7597020041834521 and std: 0.13926975118979562\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.7506108432577798 and std: 0.14845610688802685\n",
      "Loading data...\n",
      "Processing 50 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.6802184216629553 and std: 0.08923663930302032\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.7047613968447359 and std: 0.09232934734062868\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.7211590335095737 and std: 0.09985162286641609\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.7376215744437019 and std: 0.1040268251711058\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.7470506622571633 and std: 0.10962400467063275\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.7517659539586574 and std: 0.11573536475456364\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.7571551645733455 and std: 0.11652677612968852\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.7569777505556705 and std: 0.12308167105218529\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.7616211434407636 and std: 0.12063589727872809\n",
      "Epoch number: 10/15\n",
      "   Average KT score on test graphs is: 0.7606715319058751 and std: 0.12487462057155273\n",
      "Epoch number: 11/15\n",
      "   Average KT score on test graphs is: 0.7635213264064701 and std: 0.12247825541838311\n",
      "Epoch number: 12/15\n",
      "   Average KT score on test graphs is: 0.7634102078175429 and std: 0.12566590621098575\n",
      "Epoch number: 13/15\n",
      "   Average KT score on test graphs is: 0.7628082418000492 and std: 0.12824083157008276\n",
      "Epoch number: 14/15\n",
      "   Average KT score on test graphs is: 0.7702962752798194 and std: 0.1185452479602742\n",
      "Epoch number: 15/15\n",
      "   Average KT score on test graphs is: 0.7662847139890769 and std: 0.12550326409759507\n",
      "Loading data...\n",
      "Processing 50 graphs...\n",
      "Training, total Number of epoches: 15\n",
      "Epoch number: 1/15\n",
      "   Average KT score on test graphs is: 0.6742063249269237 and std: 0.09360412425681836\n",
      "Epoch number: 2/15\n",
      "   Average KT score on test graphs is: 0.7053523556315302 and std: 0.09456044155376467\n",
      "Epoch number: 3/15\n",
      "   Average KT score on test graphs is: 0.7262698016540108 and std: 0.10183527367286802\n",
      "Epoch number: 4/15\n",
      "   Average KT score on test graphs is: 0.7386584989321641 and std: 0.11172268716290956\n",
      "Epoch number: 5/15\n",
      "   Average KT score on test graphs is: 0.7478071236300031 and std: 0.11608769602214826\n",
      "Epoch number: 6/15\n",
      "   Average KT score on test graphs is: 0.7451846463745688 and std: 0.1289474008724505\n",
      "Epoch number: 7/15\n",
      "   Average KT score on test graphs is: 0.7477401619138804 and std: 0.13317509721089563\n",
      "Epoch number: 8/15\n",
      "   Average KT score on test graphs is: 0.7555416100336038 and std: 0.13076038144737942\n",
      "Epoch number: 9/15\n",
      "   Average KT score on test graphs is: 0.7583431258226557 and std: 0.1312012565640325\n",
      "Epoch number: 10/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4d/f5lz4rj56ws3v2hlc19c60t80000gn/T/ipykernel_56539/4070086309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch number: {e+1}/{num_epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_adj_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_adj_t_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_num_node_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbc_mat_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                                 \u001b[0;31m#to check test loss while training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/tfm/tfm-GNN-Ranking/custom/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(list_adj_train, list_adj_t_train, list_num_node_train, bc_mat_train, model, device, optimizer, size)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/tfm/tfm-GNN-Ranking/custom/model_bet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, adj1, adj2)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mscore1_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mscore1_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mscore1_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mscore1_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mscore1_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/tfm/tfm-GNN-Ranking/custom/layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_vec, dropout)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mscore_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mscore_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_temp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mscore_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " \n",
    "from model_bet import *\n",
    "import pandas as pd\n",
    "\n",
    "param = {\n",
    "    \"graph_types\": [\"ER\",\"SF\",\"GRP\"],\n",
    "    \"graphs_sizes\": \"2000_1000_nodes\",\n",
    "    \"test_generation_seeds\": [10],\n",
    "    \"train_generation_seeds\": [j for j in range(5)],\n",
    "    \"test_split_seeds\": [0],\n",
    "    \"train_split_seeds\": [0],\n",
    "    \"num_copies\": [10],\n",
    "    \"adj_size\" : 10000,\n",
    "    \"num_train\" : 5,\n",
    "    \"num_test\" : 10,\n",
    "    \"model_seeds\": [15],\n",
    "    \"num_epochs\": 15,\n",
    "}\n",
    "\n",
    "Results = { \"gtype_train\":[],\n",
    "            \"train_generation_seed\": [],\n",
    "            \"train_splilt_seed\": [],\n",
    "            \"test_generation_seed\": [],\n",
    "            \"test_splilt_seed\": [],\n",
    "            \"copies\":[],\n",
    "            \"adj_size\": [],\n",
    "            \"model_seed\": [],\n",
    "            \"epochs\": [],\n",
    "            \"kendalltau\":[],\n",
    "            \"std\":[]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for testgenseed in param[\"test_generation_seeds\"]:\n",
    "    for testsplitseed in param[\"test_split_seeds\"]:\n",
    "        \n",
    "        test_file = f\"{graph_type}_{param['num_test']}_graphs_{param['graphs_sizes']}_{testgenseed}_genseed_{param['num_test']}_test_{param['adj_size']}_size_{testsplitseed}_splitseed.pickle\"\n",
    "        #Load test data\n",
    "        with open(\"./delivery/data_splits/test/\"+test_file,\"rb\") as fopen:\n",
    "            list_graph_test,list_n_seq_test,list_num_node_test,bc_mat_test,deg_mat_test = pickle.load(fopen)\n",
    "\n",
    "        list_adj_test,list_adj_t_test = graph_to_adj_bet(list_graph_test,list_n_seq_test,list_num_node_test,param['adj_size'])\n",
    "\n",
    "        for graph_type in param[\"graph_types\"]:\n",
    "            for traingenseed in param[\"train_generation_seeds\"]:\n",
    "                for trainsplitseed in param[\"train_split_seeds\"]:\n",
    "                    for num_copies in param[\"num_copies\"]:\n",
    "                        \n",
    "                        train_file = f\"{graph_type}_{param['num_train']}_graphs_{param['graphs_sizes']}_{traingenseed}_genseed_{param['num_train']}_train_{num_copies}_copies_{param['adj_size']}_size_{trainsplitseed}_splitseed.pickle\"\n",
    "\n",
    "                        #Load training data\n",
    "                        print(f\"Loading data...\")\n",
    "                        with open(\"./delivery/data_splits/train/\"+train_file,\"rb\") as fopen:\n",
    "                            list_graph_train,list_n_seq_train,list_num_node_train,bc_mat_train,deg_mat_train = pickle.load(fopen)\n",
    "\n",
    "                        list_adj_train,list_adj_t_train = graph_to_adj_bet(list_graph_train,list_n_seq_train,list_num_node_train,param['adj_size'])\n",
    "\n",
    "                        model_size = bc_mat_train.shape[0]\n",
    "                        assert model_size == param['adj_size']\n",
    "                        \n",
    "                        for model_seed in param[\"model_seeds\"]:\n",
    "                            #Model parameters\n",
    "\n",
    "                            torch.manual_seed(model_seed)\n",
    "                            \n",
    "                            hidden = 20\n",
    "                            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                            model = GNN_Bet(ninput=model_size,nhid=hidden,dropout=0.6)\n",
    "                            model.to(device)\n",
    "\n",
    "                            optimizer = torch.optim.Adam(model.parameters(),lr=0.0005)\n",
    "                            num_epoch = param[\"num_epochs\"]\n",
    "\n",
    "                            print(f\"Training, total Number of epoches: {num_epoch}\")\n",
    "                            for e in range(num_epoch):\n",
    "                                print(f\"Epoch number: {e+1}/{num_epoch}\")\n",
    "                                train(list_adj_train,list_adj_t_train,list_num_node_train,bc_mat_train,model,device,optimizer,model_size)\n",
    "\n",
    "                                #to check test loss while training\n",
    "                                with torch.no_grad():\n",
    "                                    r = test(list_adj_test,list_adj_t_test,list_num_node_test,bc_mat_test,deg_mat_test,model,device,model_size)\n",
    "\n",
    "                                Results[\"gtype_train\"].append(train_file)\n",
    "                                Results[\"train_generation_seed\"].append(traingenseed)\n",
    "                                Results[\"train_splilt_seed\"].append(trainsplitseed)\n",
    "                                Results[\"test_generation_seed\"].append(testgenseed)\n",
    "                                Results[\"test_splilt_seed\"].append(testsplitseed)\n",
    "                                Results[\"copies\"].append(num_copies)\n",
    "                                Results[\"adj_size\"].append(model_size)\n",
    "                                Results[\"model_seed\"].append(model_seed)\n",
    "                                Results[\"epochs\"].append(e)\n",
    "                                Results[\"kendalltau\"].append(r[\"kt\"])\n",
    "                                Results[\"std\"].append(r[\"std\"])\n",
    "\n",
    "                                df = pd.DataFrame.from_dict(Results)\n",
    "                                df.to_csv(\"./delivery/output_synthetic_graphs_performance_variating_random_seeds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "836981034a4078c9f81aa3bbf2605e6a2991c189feb0614c725b1b8d5991d7f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
