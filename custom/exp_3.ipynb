{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We generate the ER graphs for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "random.seed(1)\n",
    "\n",
    "'''\n",
    "\n",
    "This code generates different ER graphs for scalability test\n",
    "In order to keep the same data sctructure used we generate the centrality dictionary with 0 bet for all the nodes for avoiding computations since the bet value is not relevant for this experiment\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Generating some Erdos-Renyi graphs for scalability tests\n",
    "\n",
    "nodes = [100000,200000,300000,400000,500000,600000,700000,800000,900000,1000000]\n",
    "edges = [2,4,6]\n",
    "\n",
    "for n in nodes:\n",
    "    for e in edges:\n",
    "        list_bet_data = list()\n",
    "        p = e/n\n",
    "\n",
    "        print(f\"Generating ER graph: {n} nodes, {e} avg edges\")\n",
    "        g_nx = nx.generators.random_graphs.fast_gnp_random_graph(n,p = p,directed = True)\n",
    "        if nx.number_of_isolates(g_nx)>0:\n",
    "            g_nx.remove_nodes_from(list(nx.isolates(g_nx)))\n",
    "        g_nx = nx.convert_node_labels_to_integers(g_nx)\n",
    "        g_nkit = nx2nkit(g_nx)\n",
    "        bet_dict = {j:0 for j in g_nkit.iterNodes()} # We set the betweenness data to 0 sinnce we don't need it for this experiment\n",
    "        deg_dict = {j:0 for j in g_nkit.iterNodes()} # the same\n",
    "        list_bet_data.append([g_nx,bet_dict,deg_dict])\n",
    "\n",
    "        fname_bet = f\"./graphs_scalability_test/ER_1_graph_{n}_nodes_{e}_edges.pickle\"\n",
    "\n",
    "        with open(fname_bet,\"wb\") as fopen:\n",
    "            pickle.dump(list_bet_data,fopen)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nodes = [100000,200000,300000,400000,500000,600000,700000,800000,900000,1000000]\n",
    "edges = [2,4,6]\n",
    "\n",
    "results = []\n",
    "\n",
    "#for n in nodes:\n",
    "#    for e in edges:\n",
    "#        print(f\"Processing graph {n} nodes and {e} edges.\")\n",
    "#        file = f'ER_1_graph_{n}_nodes_{e}_edges.pickle'\n",
    "#        #Load data\n",
    "#        with open(f\"./data_splits_scalability_test/{file}\",\"rb\") as fopen:\n",
    "#            list_graph_test,list_n_seq_test,list_num_node_test,bc_mat_test,deg_mat_test = pickle.load(fopen)\n",
    "#\n",
    "#        model_size = bc_mat_test.shape[0]\n",
    "#\n",
    "#        #Get adjacency matrices from graphs\n",
    "#        print(f\"Graphs to adjacency conversion.\")\n",
    "#        starting = time.time()\n",
    "#        list_adj_test,list_adj_t_test = graph_to_adj_bet(list_graph_test,list_n_seq_test,list_num_node_test,model_size)\n",
    "#        end = time.time()\n",
    "#\n",
    "#        results.append({\"n\": n, \"e\": e, \"t\": round(end-starting,4)})\n",
    "\n",
    "#with open(f\"auxresults.pickle\",\"wb\") as fopen:\n",
    "#            pickle.dump(results,fopen)\n",
    "\n",
    "\n",
    "with open(f\"auxresults.pickle\",\"rb\") as fopen:\n",
    "    results = pickle.load(fopen)\n",
    "\n",
    "\n",
    "line_2 = []\n",
    "line_4 = []\n",
    "line_6 = []\n",
    "xs = []\n",
    "\n",
    "for j in results:\n",
    "    if j[\"e\"] == 2:\n",
    "        line_2.append([j['n'],j['t']])\n",
    "    elif j[\"e\"] == 4:\n",
    "        line_4.append([j['n'],j['t']])\n",
    "    else:\n",
    "        line_6.append([j['n'],j['t']])\n",
    "\n",
    "print(line_2)\n",
    "print(line_4)\n",
    "print(line_6)\n",
    "\n",
    "\n",
    "xs = [j[0]/100000 for j in line_2]\n",
    "ys = [j[1] for j in line_2]\n",
    "plt.plot(xs,ys,color='r',label='Ratio_2')\n",
    "plt.scatter(xs,ys,color='r')\n",
    "\n",
    "xs = [j[0]/100000 for j in line_4]\n",
    "ys = [j[1] for j in line_4]\n",
    "plt.plot(xs,ys,color='b',label='Ratio_4')\n",
    "plt.scatter(xs,ys,color='b')\n",
    "\n",
    "xs = [j[0]/100000 for j in line_6]\n",
    "ys = [j[1] for j in line_6]\n",
    "plt.plot(xs,ys,color='g',label='Ratio_6')\n",
    "plt.scatter(xs,ys,color='g')\n",
    "\n",
    "plt.legend()\n",
    "plt.ticklabel_format(axis='x',scilimits=(0,10))\n",
    "plt.xlabel(\"Number of Nodes ( x 10$^5$ )\")\n",
    "plt.ylabel(\"Time(s)\")\n",
    "#plt.savefig(\"plots/exp-3-scalability.png\",dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
